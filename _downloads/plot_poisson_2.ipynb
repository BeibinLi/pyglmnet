{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n# Canonical Poisson Distribution\n\n\nThis is an example demonstrating how pyglmnet with\npoisson exponential distribution works.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "First, we can import useful libraries that we will use it later on\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import numpy as np\nimport scipy.sparse as sps\nfrom scipy.special import expit\nfrom copy import deepcopy\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Import ``GLM`` class from ``pyglmnet``\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# import GLM model\nfrom pyglmnet import GLM\n\n# create regularization parameters for model\nreg_lambda = np.logspace(np.log(0.5), np.log(0.01), 10, base=np.exp(1))\nglm_poissonexp = GLM(distr='poissonexp', verbose=False, alpha=0.05,\n            max_iter=1000, learning_rate=1e-5,\n            reg_lambda=reg_lambda, eta=4.0)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n\n$$J = \\sum_i \\lambda_i - y_i \\log \\lambda_i$$\n\nwhere\n\n$$\\lambda_i =\n    \\begin{cases}\n        \\exp(z_i), & \\text{if}\\ z_i \\leq \\eta \\\\\n        \\\\\n         \\exp(\\eta)z_i + (1-\\eta)\\exp(\\eta), & \\text{if}\\ z_i \\gt \\eta\n    \\end{cases}$$\n\nand\n\n$$z_i = \\beta_0 + \\sum_j \\beta_j x_{ij}$$\n\nTaking gradients,\n\n$$\\frac{\\partial J}{\\partial \\beta_j} = \\sum_i \\frac{\\partial J}{\\partial \\lambda_i} \\frac{\\partial \\lambda_i}{\\partial z_i} \\frac{\\partial z_i}{\\partial \\beta_j}$$\n\n\n$$\\frac{\\partial J}{\\partial \\beta_0} =\n    \\begin{cases}\n        \\sum_i \\Big(\\lambda_i - y_i\\Big), & \\text{if}\\ z_i \\leq \\eta \\\\\n        \\\\\n        \\exp(\\eta) \\sum_i \\Big(1 - \\frac{\\lambda_i}{y_i}\\Big), & \\text{if}\\ z_i \\gt \\eta\n    \\end{cases}$$\n\n$$\\frac{\\partial J}{\\partial \\beta_j} =\n    \\begin{cases}\n        \\sum_i \\Big(\\lambda_i - y_i\\Big)x_{ij}, & \\text{if}\\ z_i \\leq \\eta \\\\\n        \\\\\n        \\exp(\\eta) \\sum_i \\Big(1 - \\frac{\\lambda_i}{y_i}\\Big)x_{ij}, & \\text{if}\\ z_i \\gt \\eta\n    \\end{cases}$$\n\n\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "z = np.linspace(0., 10., 100)\n\neta = 4.0\nqu = deepcopy(z)\nslope = np.exp(eta)\nintercept = (1 - eta) * slope\nqu[z > eta] = z[z > eta] * slope + intercept\nqu[z <= eta] = np.exp(z[z <= eta])\n\nplt.plot(z, qu, label='a')\nplt.plot(z, np.exp(z), label='b')\nplt.ylim([0, 1000])\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=1,\n           ncol=2, borderaxespad=0.)\nplt.show()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Dataset size\nn_samples, n_features = 10000, 100\n\n# baseline term\nbeta0 = np.random.normal(0.0, 1.0, 1)\n# sparse model terms\nbeta = sps.rand(n_features, 1, 0.1)\nbeta = np.array(beta.todense())\n\n# training data\nXr = np.random.normal(0.0, 1.0, [n_samples, n_features])\nyr = glm_poissonexp.simulate(beta0, beta, Xr)\n\n# testing data\nXt = np.random.normal(0.0, 1.0, [n_samples, n_features])\nyt = glm_poissonexp.simulate(beta0, beta, Xt)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Fit model to training data\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "scaler = StandardScaler().fit(Xr)\nglm_poissonexp.fit(scaler.transform(Xr),yr);"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Gradient of loss function\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "grad_beta0, grad_beta = glm_poissonexp._grad_L2loss(glm_poissonexp.fit_[-1]['beta0'], glm_poissonexp.fit_[-1]['beta'], 0.01, Xr, yr)\nprint(grad_beta[:5])"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Use one model to predict\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "m = glm_poissonexp[-1]\nthis_model_param = m.fit_\nyrhat = m.predict(scaler.transform(Xr))\nythat = m.predict(scaler.transform(Xt))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Visualize predicted output\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "plt.plot(yt[:100], label='tr')\nplt.plot(ythat[:100], 'r', label='pr')\nplt.xlabel('samples')\nplt.ylabel('true and predicted outputs')\nplt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=1,\n           ncol=2, borderaxespad=0.)\nplt.show()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "compute pseudo R-square\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "print(m.score(yt, ythat, np.mean(yr), method='pseudo_R2'))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.11", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}