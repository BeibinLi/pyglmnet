{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n# Group Lasso Example\n\n\nThis is an example demonstrating Pyglmnet with\nmultinomial the group lasso regularization, typical in regression\nproblems where it is reasonable to impose penalties to model parameters\nin a group-wise fashion based on domain knowledge.\n\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from pyglmnet import GLM\nfrom pyglmnet.datasets import fetch_group_lasso_datasets\nimport numpy as np\nimport random"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\nGroup Lasso Example\nsimilar to method found in:\nftp://ftp.stat.math.ethz.ch/Manuscripts/buhlmann/lukas-sara-peter.pdf\n\nThe task here is to determine which base pairs and positions within a 7-mer\nsequence are most important to predicting if the sequence contains a splice\nsite or not.\n\n#########################################################\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "print(\"Retrieving data...\")\n\ndf , group_idxs= fetch_group_lasso_datasets()\n\n\nprint(\"Data retrieved\")\nprint(\"Dataframe: \")\nprint(df.head())\n\n#set up the group lasso GLM model\n\ngl_glm = GLM(distr=\"binomial\",\n             group=group_idxs,\n             tol=1e-2,\n             score_metric=\"pseudo_R2\",\n             alpha=1.0,\n             reg_lambda=np.logspace(np.log(100), np.log(0.01), 5, base=np.exp(1)))\n\n\n#set up the non group GLM model\n\nglm = GLM(distr=\"binomial\",\n          tol=1e-2,\n          score_metric=\"pseudo_R2\",\n          alpha=1.0,\n          reg_lambda=np.logspace(np.log(100), np.log(0.01), 5, base=np.exp(1)))\n\nprint(\"gl_glm: \", gl_glm)\nprint(\"glm: \", glm)\n\n# Set up the training and testing sets.\nX = df[df.columns.difference([\"Label\"]).values]\n\ntest_idxs = random.sample(list(range(X.shape[0])), 1000)\ntrain_idxs = list( set(list(range(X.shape[0]))).difference(set(test_idxs)) )\n\nX_train = X.iloc[train_idxs, :]\nX_test = X.iloc[test_idxs, :]\n\ny = df.loc[:, \"Label\"]\ny_train = y.iloc[train_idxs]\ny_test = y.iloc[test_idxs]\n\n\nprint(\"Fitting models\")\ngl_glm.fit(X_train.values, y_train.values)\nglm.fit(X_train.values, y_train.values)\nprint(\"Model fitting complete.\")\nprint(\"\\n\\n\")\n\n\nprint(\"Group lasso post fitting score: \", gl_glm.score(X_test.values, y_test.values))\nprint(\"Non-group lasso post fitting score: \", glm.score(X_test.values, y_test.values))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.11", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}