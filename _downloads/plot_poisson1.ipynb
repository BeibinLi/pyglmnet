{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n=================================\nPoisson (Basic) Distribution\n=================================\n\nThis is an example demonstrating how pyglmnet\nworks with a basic Poisson distribution.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "First, we can import useful libraries that we will use it later on.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Author: Pavan Ramkumar <pavan.ramkumar@gmail.com>\n# License: MIT\n\nimport numpy as np\nimport scipy.sparse as sps\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Here are inputs that you can provide when you instantiate the `GLM` class.\nIf not provided, it will be set to the respective defaults\n\n- `distr`: str (`'poisson'` or `'normal'` or `'binomial'` or `'multinomial'`)\n    default: `'poisson'`\n- `alpha`: float (the weighting between L1 and L2 norm)\n    default: 0.5\n- `reg_lambda`: array (array of regularized parameters)\n    default: `np.logspace(np.log(0.5), np.log(0.01), 10, base=np.exp(1))`\n- `learning_rate`: float (learning rate for gradient descent)\n    default: 1e-4\n- `max_iter`: int (maximum iteration for the model)\n    default: 100\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "Import ``GLM`` class from ``pyglmnet``\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# import GLM model\nfrom pyglmnet import GLM\n\n# create regularize parameters for model\nreg_lambda = np.logspace(np.log(0.5), np.log(0.01), 10, base=np.exp(1))\nglm_poisson = GLM(distr='poisson', verbose=False, alpha=0.05,\n            max_iter=1000, learning_rate=1e-4,\n            reg_lambda=reg_lambda)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Simulate a dataset\n------------------\nThe ``GLM`` class has a very useful method called ``simulate()``.\n\nSince a canonical link function is already specified by the distribution\nparameters, or provided by the user, ``simulate()`` requires\nonly the independent variables ``X`` and the coefficients ``beta0``\nand ``beta``\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "n_samples, n_features = 10000, 100\n\n# coefficients\nbeta0 = np.random.normal(0.0, 1.0, 1)\nbeta = sps.rand(n_features, 1, 0.1)\nbeta = np.array(beta.todense())\n\n# training data\nXr = np.random.normal(0.0, 1.0, [n_samples, n_features])\nyr = glm_poisson.simulate(beta0, beta, Xr)\n\n# testing data\nXt = np.random.normal(0.0, 1.0, [n_samples, n_features])\nyt = glm_poisson.simulate(beta0, beta, Xt)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Fit the model\n^^^^^^^^^^^^^\nFitting the model is accomplished by a single GLM method called `fit()`.\nYou can provide data and output pair `(X, y)` i.e.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "scaler = StandardScaler().fit(Xr)\nglm_poisson.fit(scaler.transform(Xr), yr)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Visualize the fit coefficients\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nThe estimated coefficients are stored in an instance variable called ``.fit_``\nwhich is a list of dictionaries. Each dictionary corresponds to a\nparticular ``reg_lambda``\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "fit_param = glm_poisson[0].fit_\nplt.plot(beta[:], 'bo', label ='bo')\nplt.plot(fit_param['beta'][:], 'ro', label='ro')\nplt.xlabel('samples')\nplt.ylabel('outputs')\nplt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=1,\n           ncol=2, borderaxespad=0.)\nplt.show()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Slicing the model object\n^^^^^^^^^^^^^^^^^^^^^^^^\nAlthough the model is fit to all values of reg_lambda specified by a regularization\npath, often we are only interested in further analysis for a particular value of\n``reg_lambda``. We can easily do this by slicing the object.\n\nFor instance model[0] returns an object identical to model but with ``.fit_``\nas a dictionary corresponding to the estimated coefficients for ``reg_lambda[0]``.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "Make predictions based on fit model\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nThe ``predict()`` method takes two parameters: a numpy 2d array of independent\nvariables and a dictionary of fit parameters. It returns a vector of\npredicted targets.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Predict targets from test set\nyrhat = glm_poisson[0].predict(scaler.transform(Xr))\nythat = glm_poisson[0].predict(scaler.transform(Xt))\n\nplt.plot(yt[:100], label='tr')\nplt.plot(ythat[:100], 'r', label='pr')\nplt.xlabel('samples')\nplt.ylabel('true and predicted outputs')\nplt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=1,\n           ncol=2, borderaxespad=0.)\nplt.show()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Goodness of fit\n^^^^^^^^^^^^^^^\nThe GLM class provides two methods for evaluating goodness of fit: ``deviance()``\nand ``pseudo_R2()``. Both of them require the true targets and the predicted targets\nas inputs. ``pseudo_R2()`` additionally requires a null model, which is typically\nthe mean of the target variables in the training set.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Compute model deviance\nDr = glm_poisson[0].score(yr, yrhat)\nDt = glm_poisson[0].score(yt, ythat)\nprint('Dr = %f' % Dr, 'Dt = %f' % Dt)\n\n# Compute pseudo-R2s\nR2r = glm_poisson[0].score(yr, yrhat, np.mean(yr), method='pseudo_R2')\nR2t = glm_poisson[0].score(yt, ythat, np.mean(yr), method='pseudo_R2')\nprint('  R2r =  %f' % R2r, ' R2r = %f' % R2t)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Multinomial example\n^^^^^^^^^^^^^^^^^^^\nWe can also use ``pyglmnet`` with multinomial case\nwhere you can provide array of class.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from sklearn.datasets import make_classification\nX, y = make_classification(n_samples=10000, n_classes=5,\n                           n_informative=100, n_features=100, n_redundant=0)\n\nglm_mn = GLM(distr='multinomial', alpha=0.01,\n               reg_lambda=np.array([0.02, 0.01]), verbose=False)\nglm_mn.threshold = 1e-5\nglm_mn.fit(X, y)\ny_pred = glm_mn[-1].predict(X).argmax(axis=1)\nprint('Output performance = %f percent.' % (y_pred == y).mean())"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.11", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}